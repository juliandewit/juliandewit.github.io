---
layout:     post
title:      "2rd place solution for the 2017 national datascience bowl"
date:       2017-04-14 00:00:00
author:     "Julian de Wit"
---


## Summary
This document describes my part of the 2rd prize solution to the [Data Science Bowl 2017](https://www.kaggle.com/c/data-science-bowl-2017/) hosted by Kaggle.com. I teamed up with Daniel Hammack. His part of the solution is decribed [here](https://www.google.com/) The goal of the challenge was to predict the development of lung cancer in a patient given a set of CT images. Detailed descriptions of the challenge can be found on the [Kaggle competition page](https://www.kaggle.com/c/data-science-bowl-2017#description) and [this blog post](https://eliasvansteenkiste.github.io/machine%20learning/lung-cancer-pred/) by Elias Vansteenkiste. My solution (and that of Daniel) was mainly based on nodule detectors with a 3D convolutional neural network architecture.


## First experiments and the resulting "plan of attack"
Before joining the competition I first watched the [video by Bram van Ginneken on lung CT images](https://www.youtube.com/watch?v=-XUKq3B4sdw) to get a feel for the problem. I tried to mannually asses a few scans and comcluded that this was a hard problem where you almost literally had to find a needle in a haystack. Like described by [Elias Vansteenkiste](https://eliasvansteenkiste.github.io/machine%20learning/lung-cancer-pred/) the amount of signal vs noise was almost 1:1000.000. As the first efforts on the formums showed, and contrary to all the AI hype about deep learning, the neural nets were not able to learn someting from the raw image data. There were only 1300 cases to train on and the label "Cancer Y/N" was to distant from the actual features in the images for the network to latch upon. 

The solution would be to spoonfeed a neural network with examples with a better signal/noise ratio and a more direct relation between the labels and the features. Luckily the competition organizers already pointed us to a previous competition called [LUNA16](https://luna16.grand-challenge.org/). For this dataset doctors had meticulously labeled more than 1000 lung nodules in more than 800 patient scans. The LUNA16 competition also provided more then 500.000 non-nodule annotations. So when you crop small 3D chunks around the annotations from the big CT scans you end up with much smaller 3D images with a more direct labels (nodule Y/N). The LUNA 16 data also contained size information. As the size usually is a good predictor of malignancy I thought this would be a useful starting point.


![The plan](/images/plan2017.png)
*Figure 1. The idealized version of my approach*

After my success with U-nets in the [previous datascience bowl](http://juliandewit.github.io/kaggle-ndsb/) my first idea was to try these. This worked better for detecting nodules but the 2D version gave a lot of false positives. As I already experienced during my manual efforts that you had to view the scans in sequence to better assess if a bright spot was a nodule or just a vein. So then I switced to a 3D U-net. However the 3D U-net was very heavy and I like to do quick experiments. U-nets give a very detailed probability map while I was only interested in a very rough estimate. So I cut off the upstream part of the U-net which was basically a normal conv net.

